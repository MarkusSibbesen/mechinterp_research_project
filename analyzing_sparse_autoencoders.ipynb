{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "try:\n",
    "    has_changed_dir\n",
    "except:\n",
    "    has_changed_dir = False\n",
    "\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"Running as a Colab notebook\")\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    %pip install datasets\n",
    "    %pip install translate-toolkit\n",
    "    %pip install bitsandbytes\n",
    "\n",
    "    !git clone https://github.com/MarkusSibbesen/mechinterp_research_project.git\n",
    "\n",
    "    if not has_changed_dir:\n",
    "        os.chdir('mechinterp_research_project')\n",
    "        has_changed_dir = True\n",
    "else:\n",
    "    if not has_changed_dir:\n",
    "        os.chdir('.')\n",
    "        has_changed_dir = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import json\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from src.dataset_handling import TextClassificationDataset\n",
    "from src.utils import get_activations_and_labels, get_hidden_activations\n",
    "from src.sparse_autoencoders import SAE_topk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_url = \"EleutherAI/pythia-14m\"\n",
    "model_name = model_url.split('/')[-1]\n",
    "hookpoint_name = 'gpt_neox.layers.$.mlp.act'\n",
    "layer = 3\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_url).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_url)\n",
    "\n",
    "num_hookpoints = model.config.num_hidden_layers\n",
    "hookpoint = hookpoint_name.replace('$', str(layer))\n",
    "input_size = model.config.intermediate_size\n",
    "\n",
    "data_path = 'data/split/tedtalks_test.tsv'\n",
    "dataset = TextClassificationDataset.from_tsv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_acts_outfolder = 'results/sparse_autoencoder_activations'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expansion_factor = 4\n",
    "k = 20\n",
    "\n",
    "meta_data = {\n",
    "    'input_size': input_size,\n",
    "    'hidden_size': input_size * expansion_factor,\n",
    "    'k': k\n",
    "}\n",
    "\n",
    "sae = SAE_topk(meta_data=meta_data)\n",
    "\n",
    "sae.load_state_dict(torch.load(f'models/sparse_autoencoders/pythia-14m/topk{k}/{hookpoint}.pt', weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_acts = []\n",
    "da_preacts = []\n",
    "da_tokens = []\n",
    "en_acts = []\n",
    "en_preacts = []\n",
    "en_tokens = []\n",
    "\n",
    "for i in range(100):\n",
    "\n",
    "    sent, label = dataset[i]\n",
    "\n",
    "    tokenized = [\n",
    "        tokenizer(input_, return_tensors='pt').to(device)\n",
    "        for input_ in [sent]\n",
    "    ]\n",
    "\n",
    "    transformer_acts = get_hidden_activations(model, hookpoint, tokenized)\n",
    "\n",
    "    sae_preacts = sae.get_preacts(transformer_acts)\n",
    "    sae_acts = sae.get_activations(transformer_acts)\n",
    "\n",
    "    for act_indices, preacts, token in zip(sae_acts.indices, sae_preacts, tokenized[0]['input_ids'][0]):\n",
    "\n",
    "        zeros = torch.zeros(input_size * expansion_factor)\n",
    "\n",
    "        zeros[act_indices] = 1\n",
    "\n",
    "        if label == 0:\n",
    "            da_acts.append(zeros)\n",
    "            da_preacts.append(preacts)\n",
    "            da_tokens.append(token.item())\n",
    "        else:\n",
    "            en_acts.append(zeros)\n",
    "            en_preacts.append(preacts)\n",
    "            en_tokens.append(token.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_word_init_acts = []\n",
    "da_word_init_preacts = []\n",
    "\n",
    "for token, acts, preacts in zip(da_tokens, da_acts, da_preacts):\n",
    "    if tokenizer.convert_ids_to_tokens(token).startswith('Ġ'):\n",
    "        da_word_init_acts.append(acts)\n",
    "        da_word_init_preacts.append(preacts)\n",
    "    \n",
    "\n",
    "en_word_init_acts = []\n",
    "en_word_init_preacts = []\n",
    "\n",
    "for token, acts, preacts in zip(en_tokens, en_acts, en_preacts):\n",
    "    if tokenizer.convert_ids_to_tokens(token).startswith('Ġ'):\n",
    "        en_word_init_acts.append(acts)\n",
    "        en_word_init_preacts.append(preacts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TEXT PRINTING\n",
    "\n",
    "def format_chars(text):\n",
    "    formatted = (\n",
    "        text.replace('Ġ', ' ').\n",
    "            replace('Ã¥', 'å').\n",
    "            replace('Ã¦', 'æ').\n",
    "            replace('Ã¸', 'ø')\n",
    "    )\n",
    "    return formatted\n",
    "\n",
    "\n",
    "# absolute genius stuff form chatgpt\n",
    "\n",
    "def rgb_text(text, r, g, b, background=False):\n",
    "    \"\"\"Returns text formatted with 24-bit RGB color.\"\"\"\n",
    "    if background:\n",
    "        if (r + g + b) / 3 > 128:\n",
    "            return f\"\\033[38;2;0;0;0m\\033[48;2;{r};{g};{b}m{text}\\033[0m\" \n",
    "        else:\n",
    "            return f\"\\033[48;2;{r};{g};{b}m{text}\\033[0m\"\n",
    "    return f\"\\033[38;2;{r};{g};{b}m{text}\\033[0m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[48;2;116;0;0mT\u001b[0m\u001b[48;2;112;0;0mSA\u001b[0m\u001b[48;2;64;0;0m âĢĶ\u001b[0m\u001b[48;2;99;0;0m thousands\u001b[0m\u001b[48;2;18;0;0m standing\u001b[0m\u001b[48;2;114;0;0m around\u001b[0m\u001b[48;2;113;0;0m.\u001b[0m\u001b[48;2;46;0;0m \u001b[0m\u001b[48;2;110;0;0mNo\u001b[0m\u001b[48;2;68;0;0m one\u001b[0m\u001b[48;2;97;0;0m's\u001b[0m\u001b[48;2;4;0;0m really\u001b[0m\u001b[48;2;45;0;0m going\u001b[0m\u001b[48;2;52;0;0m to\u001b[0m\u001b[48;2;28;0;0m bother\u001b[0m\u001b[48;2;89;0;0m you\u001b[0m\u001b[48;2;112;0;0m.\u001b[0m\u001b[48;2;51;0;0m \"\"\u001b[0m\u001b[48;2;138;0;0m So\u001b[0m\u001b[48;2;145;0;0m one\u001b[0m\n",
      "\u001b[48;2;89;0;0m of\u001b[0m\u001b[48;2;112;0;0m the\u001b[0m\u001b[48;2;102;0;0m things\u001b[0m\u001b[48;2;74;0;0m that\u001b[0m\u001b[48;2;70;0;0m I\u001b[0m\u001b[48;2;82;0;0m do\u001b[0m\u001b[48;2;86;0;0m is\u001b[0m\u001b[48;2;78;0;0m I\u001b[0m\u001b[48;2;102;0;0m actually\u001b[0m\u001b[48;2;7;0;0m look\u001b[0m\u001b[48;2;74;0;0m through\u001b[0m\u001b[48;2;59;0;0m my\u001b[0m\u001b[48;2;129;0;0m server\u001b[0m\u001b[48;2;64;0;0m logs\u001b[0m\u001b[48;2;47;0;0m very\u001b[0m\u001b[48;2;40;0;0m carefully\u001b[0m\u001b[48;2;37;0;0m.\u001b[0m\u001b[48;2;57;0;0m \u001b[0m\u001b[48;2;102;0;0mWe\u001b[0m\u001b[48;2;81;0;0m have\u001b[0m\n",
      "\u001b[48;2;85;0;0m satellite\u001b[0m\u001b[48;2;68;0;0m maps\u001b[0m\u001b[48;2;63;0;0m where\u001b[0m\u001b[48;2;87;0;0m we\u001b[0m\u001b[48;2;65;0;0m can\u001b[0m\u001b[48;2;61;0;0m see\u001b[0m\u001b[48;2;87;0;0m where\u001b[0m\u001b[48;2;101;0;0m people\u001b[0m\u001b[48;2;77;0;0m are\u001b[0m\u001b[48;2;73;0;0m and\u001b[0m\u001b[48;2;105;0;0m where\u001b[0m\u001b[48;2;78;0;0m they\u001b[0m\u001b[48;2;94;0;0m're\u001b[0m\u001b[48;2;76;0;0m moving\u001b[0m\u001b[48;2;112;0;0m.\u001b[0m\u001b[48;2;54;0;0m \u001b[0m\u001b[48;2;110;0;0mNow\u001b[0m\u001b[48;2;111;0;0m the\u001b[0m\u001b[48;2;27;0;0m really\u001b[0m\u001b[48;2;50;0;0m interesting\u001b[0m\n",
      "\u001b[48;2;90;0;0m thing\u001b[0m\u001b[48;2;92;0;0m about\u001b[0m\u001b[48;2;44;0;0m these\u001b[0m\u001b[48;2;108;0;0m reactors\u001b[0m\u001b[48;2;43;0;0m is\u001b[0m\u001b[48;2;82;0;0m they\u001b[0m\u001b[48;2;59;0;0m're\u001b[0m\u001b[48;2;0;0;0m built\u001b[0m\u001b[48;2;42;0;0m in\u001b[0m\u001b[48;2;28;0;0m a\u001b[0m\u001b[48;2;89;0;0m factory\u001b[0m\u001b[48;2;47;0;0m.\u001b[0m\u001b[48;2;51;0;0m \u001b[0m\u001b[48;2;119;0;0m(\u001b[0m\u001b[48;2;82;0;0mL\u001b[0m\u001b[48;2;74;0;0maughter\u001b[0m\u001b[48;2;75;0;0m)\u001b[0m\u001b[48;2;125;0;0m Along\u001b[0m\u001b[48;2;110;0;0m the\u001b[0m\u001b[48;2;116;0;0m way\u001b[0m\n",
      "\u001b[48;2;90;0;0m,\u001b[0m\u001b[48;2;114;0;0m you\u001b[0m\u001b[48;2;10;0;0m lost\u001b[0m\u001b[48;2;93;0;0m something\u001b[0m\u001b[48;2;38;0;0m.\u001b[0m\u001b[48;2;60;0;0m \u001b[0m\u001b[48;2;109;0;0mOn\u001b[0m\u001b[48;2;110;0;0m the\u001b[0m\u001b[48;2;122;0;0m evening\u001b[0m\u001b[48;2;71;0;0m of\u001b[0m\u001b[48;2;86;0;0m the\u001b[0m\u001b[48;2;112;0;0m 26\u001b[0m\u001b[48;2;104;0;0mth\u001b[0m\u001b[48;2;61;0;0m of\u001b[0m\u001b[48;2;113;0;0m August\u001b[0m\u001b[48;2;72;0;0m,\u001b[0m\u001b[48;2;108;0;0m 1928\u001b[0m\u001b[48;2;95;0;0m,\u001b[0m\u001b[48;2;58;0;0m May\u001b[0m\u001b[48;2;84;0;0m Don\u001b[0m"
     ]
    }
   ],
   "source": [
    "neuron = 398\n",
    "\n",
    "def print_colored(tokens, preacts, neuron, tokenizer, stop_after=100):\n",
    "    for idx, (token, preact) in enumerate(zip(tokens, preacts)):\n",
    "        if idx == stop_after:\n",
    "            break\n",
    "        if idx % 20 == 0:\n",
    "            print('')\n",
    "        min_preact = min(preact).item()\n",
    "        max_preact = max(preact).item()\n",
    "        formatted = format_chars(tokenizer.convert_ids_to_tokens(token))\n",
    "        value = (preact[neuron].item() - min_preact) / (max_preact - min_preact)\n",
    "        #print(value * 255)\n",
    "        print(rgb_text(formatted, r=int(value * 255), g=0, b=0, background=True), end='')\n",
    "\n",
    "\n",
    "print_colored(en_tokens, en_preacts, 398, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " standing\n",
      " really\n",
      " going\n",
      " bother\n",
      " look\n",
      " very\n",
      ".\n",
      " and\n",
      " really\n",
      " built\n",
      ".\n",
      " lost\n",
      ".\n",
      " east\n",
      " and\n",
      " ice\n",
      " ice\n",
      ".\n",
      "standing\n",
      " pro\n",
      "ver\n",
      ".\n",
      " crafting\n",
      " story\n",
      " true\n",
      " chart\n",
      " and\n",
      " discovered\n",
      " out\n",
      ",\n",
      " but\n",
      " left\n",
      ".\n",
      " \n",
      ":\n",
      " penalty\n",
      " points\n",
      " go\n",
      " crow\n",
      " \"\"\n",
      " going\n",
      " better\n",
      ".\n",
      " \"\"\n",
      " war\n",
      " and\n",
      " performance\n",
      "enh\n",
      " and\n",
      " healthy\n",
      " \n",
      " doing\n",
      " really\n",
      " important\n",
      " astr\n",
      " pointed\n",
      " in\n",
      " seeing\n",
      " ice\n",
      " melted\n",
      " going\n",
      " kill\n",
      ".\n",
      " shot\n",
      " and\n",
      " confirmed\n",
      " Type\n",
      ".\n",
      ";\n",
      " toss\n",
      " grat\n",
      " too\n",
      ")\n",
      " better\n",
      " palp\n",
      " going\n",
      " humor\n",
      " shots\n",
      " state\n",
      ".\n",
      " \n",
      " pulling\n",
      " differences\n",
      ".\n",
      " deep\n",
      " true\n",
      " affected\n",
      ".\n",
      ".\n",
      " out\n",
      ".\n",
      " yielding\n",
      " since\n",
      " began\n",
      " leave\n",
      " fossil\n",
      ".\n",
      " \n",
      ".\n",
      " sign\n",
      " road\n",
      " driving\n",
      ".\n",
      " cor\n",
      " begin\n",
      " told\n",
      ".\n",
      " \n",
      " increase\n",
      " experienced\n",
      " since\n",
      " \n",
      "urns\n",
      " in\n",
      " very\n",
      " strong\n",
      " day\n",
      ",\n",
      " but\n",
      " is\n",
      " and\n",
      ",\n",
      ".\n",
      " fascinating\n",
      " catch\n",
      " and\n",
      " wind\n",
      " only\n",
      " bl\n",
      " and\n",
      " bru\n",
      "ises\n",
      ";\n",
      " try\n",
      " save\n",
      " standing\n",
      ";\n",
      " fill\n",
      " rain\n",
      " up\n",
      " disappointment\n",
      ".\n",
      " \n",
      " blow\n",
      " found\n",
      " intro\n",
      " deliver\n",
      " better\n",
      " outcomes\n",
      " ext\n",
      ",\n",
      " managing\n",
      " proactive\n",
      " to\n",
      " run\n",
      ",\n",
      " unw\n",
      " excited\n",
      " that\n",
      " stamp\n",
      " and\n",
      " bubble\n",
      ".\n",
      " \n",
      " expectancy\n",
      " freezing\n",
      " in\n",
      ".\n",
      " points\n",
      ",\n",
      " and\n",
      " works\n",
      " beautifully\n",
      ",\n",
      " and\n",
      " work\n",
      ".\n",
      " exactly\n",
      ".\n",
      " defining\n",
      " place\n",
      " age\n",
      " Abs\n",
      " shows\n",
      ",\n",
      " try\n",
      " dist\n",
      " emotional\n",
      " image\n",
      ".\n",
      ",\n",
      " compared\n",
      " sel\n",
      ".\n",
      " visited\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for token, acts in zip(en_tokens, en_preacts):\n",
    "    if not acts[398] > threshold:\n",
    "        print(tokenizer.convert_ids_to_tokens(token).\n",
    "              replace('Ġ', ' ').\n",
    "              replace('Ã¥', 'å').\n",
    "              replace('Ã¦', 'æ').\n",
    "              replace('Ã¸', 'ø'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T\n",
      "SA\n",
      ".\n",
      "No\n",
      ".\n",
      " the\n",
      "We\n",
      ".\n",
      "Now\n",
      " the\n",
      "(\n",
      " the\n",
      "On\n",
      " the\n",
      "I\n",
      " the\n",
      "Good\n",
      "It\n",
      "'s\n",
      " the\n",
      "T\n",
      " little\n",
      " detail\n",
      "A\n",
      " can\n",
      ".\n",
      "The\n",
      " the\n",
      "That\n",
      ".\n",
      "How\n",
      "Then\n",
      " people\n",
      " that\n",
      ".\n",
      "The\n",
      " the\n",
      "Stand\n",
      ",\n",
      "We\n",
      " the\n",
      "Because\n",
      " the\n",
      "So\n",
      ",\n",
      " the\n",
      "On\n",
      "th\n",
      " the\n",
      "They\n",
      " the\n",
      "To\n",
      "But\n",
      " the\n",
      "I\n",
      " perc\n",
      " the\n",
      "So\n",
      " what\n",
      "'s\n",
      "That\n",
      "'s\n",
      " the\n",
      "Here\n",
      " you\n",
      " the\n",
      "And\n",
      " we\n",
      " will\n",
      " the\n",
      "So\n",
      " the\n",
      "Yes\n",
      "So\n",
      ",\n",
      ".\n",
      "I\n",
      " the\n",
      "And\n",
      " very\n",
      " the\n",
      "We\n",
      "It\n",
      "'s\n",
      "Now\n",
      ",\n",
      " three\n",
      ",\n",
      "We\n",
      " the\n",
      "How\n",
      " could\n",
      " we\n",
      " the\n",
      "That\n",
      "'s\n",
      "T\n",
      " the\n",
      "The\n",
      "When\n",
      " the\n",
      "And\n",
      " even\n",
      "Your\n",
      "And\n",
      " the\n",
      "This\n",
      "But\n",
      " the\n",
      "They\n",
      " the\n",
      "But\n",
      "It\n",
      " can\n",
      "We\n",
      "We\n",
      " that\n",
      "J\n",
      ":\n",
      "You\n",
      " the\n",
      "Even\n",
      " my\n",
      "Even\n",
      "On\n",
      " the\n",
      "It\n"
     ]
    }
   ],
   "source": [
    "for token, acts in zip(en_tokens, en_preacts):\n",
    "    if acts[398] > threshold:\n",
    "        print(tokenizer.convert_ids_to_tokens(token).\n",
    "              replace('Ġ', ' ').\n",
    "              replace('Ã¥', 'å').\n",
    "              replace('Ã¦', 'æ').\n",
    "              replace('Ã¸', 'ø'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_da = sum(da_acts) / len(da_acts)\n",
    "avg_en = sum(en_acts) / len(en_acts)\n",
    "\n",
    "avg_word_init_da = sum(da_word_init_acts) / len(da_word_init_acts)\n",
    "avg_word_init_en = sum(en_word_init_acts) / len(en_word_init_acts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(f'{hidden_acts_outfolder}'):\n",
    "    os.mkdir(f'{hidden_acts_outfolder}')\n",
    "\n",
    "if not os.path.isdir(f'{hidden_acts_outfolder}/{model_name}'):\n",
    "    os.mkdir(f'{hidden_acts_outfolder}/{model_name}')\n",
    "\n",
    "df = pd.DataFrame({'avg_da': avg_da.numpy(), 'avg_en': avg_en.numpy()})\n",
    "df.to_csv(f'{hidden_acts_outfolder}/{model_name}/{hookpoint}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_diff_neuron = torch.argmax(avg_da - avg_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 328,  398, 1090, 1097, 1184, 1787, 1871]),)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.where(avg_da - avg_en > 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0.2732),\n",
       " tensor(0.2668),\n",
       " tensor(0.2632),\n",
       " tensor(0.2393),\n",
       " tensor(0.2180),\n",
       " tensor(0.2149),\n",
       " tensor(0.2065),\n",
       " tensor(0.1849),\n",
       " tensor(0.1834),\n",
       " tensor(0.1789),\n",
       " tensor(0.1748),\n",
       " tensor(0.1744),\n",
       " tensor(0.1694),\n",
       " tensor(0.1652),\n",
       " tensor(0.1586),\n",
       " tensor(0.1523),\n",
       " tensor(0.1505),\n",
       " tensor(0.1495),\n",
       " tensor(0.1488),\n",
       " tensor(0.1463),\n",
       " tensor(0.1430),\n",
       " tensor(0.1377),\n",
       " tensor(0.1371),\n",
       " tensor(0.1314),\n",
       " tensor(0.1176),\n",
       " tensor(0.1155),\n",
       " tensor(0.1153),\n",
       " tensor(0.1149),\n",
       " tensor(0.1138),\n",
       " tensor(0.1124),\n",
       " tensor(0.1120),\n",
       " tensor(0.1106),\n",
       " tensor(0.1068),\n",
       " tensor(0.0949),\n",
       " tensor(0.0942),\n",
       " tensor(0.0937),\n",
       " tensor(0.0930),\n",
       " tensor(0.0918),\n",
       " tensor(0.0917),\n",
       " tensor(0.0907),\n",
       " tensor(0.0888),\n",
       " tensor(0.0864),\n",
       " tensor(0.0863),\n",
       " tensor(0.0844),\n",
       " tensor(0.0839),\n",
       " tensor(0.0831),\n",
       " tensor(0.0808),\n",
       " tensor(0.0800),\n",
       " tensor(0.0780),\n",
       " tensor(0.0775),\n",
       " tensor(0.0773),\n",
       " tensor(0.0748),\n",
       " tensor(0.0734),\n",
       " tensor(0.0724),\n",
       " tensor(0.0705),\n",
       " tensor(0.0681),\n",
       " tensor(0.0679),\n",
       " tensor(0.0663),\n",
       " tensor(0.0651),\n",
       " tensor(0.0629),\n",
       " tensor(0.0620),\n",
       " tensor(0.0615),\n",
       " tensor(0.0609),\n",
       " tensor(0.0598),\n",
       " tensor(0.0595),\n",
       " tensor(0.0586),\n",
       " tensor(0.0562),\n",
       " tensor(0.0552),\n",
       " tensor(0.0537),\n",
       " tensor(0.0532),\n",
       " tensor(0.0520),\n",
       " tensor(0.0512),\n",
       " tensor(0.0511),\n",
       " tensor(0.0506),\n",
       " tensor(0.0505),\n",
       " tensor(0.0430),\n",
       " tensor(0.0428),\n",
       " tensor(0.0408),\n",
       " tensor(0.0386),\n",
       " tensor(0.0369),\n",
       " tensor(0.0346),\n",
       " tensor(0.0322),\n",
       " tensor(0.0287),\n",
       " tensor(0.0266),\n",
       " tensor(0.0262),\n",
       " tensor(0.0249),\n",
       " tensor(0.0235),\n",
       " tensor(0.0219),\n",
       " tensor(0.0213),\n",
       " tensor(0.0196),\n",
       " tensor(0.0187),\n",
       " tensor(0.0175),\n",
       " tensor(0.0150),\n",
       " tensor(0.0144),\n",
       " tensor(0.0143),\n",
       " tensor(0.0142),\n",
       " tensor(0.0133),\n",
       " tensor(0.0131),\n",
       " tensor(0.0125),\n",
       " tensor(0.0125),\n",
       " tensor(0.0119),\n",
       " tensor(0.0118),\n",
       " tensor(0.0117),\n",
       " tensor(0.0117),\n",
       " tensor(0.0113),\n",
       " tensor(0.0112),\n",
       " tensor(0.0111),\n",
       " tensor(0.0108),\n",
       " tensor(0.0106),\n",
       " tensor(0.0105),\n",
       " tensor(0.0105),\n",
       " tensor(0.0104),\n",
       " tensor(0.0094),\n",
       " tensor(0.0094),\n",
       " tensor(0.0093),\n",
       " tensor(0.0088),\n",
       " tensor(0.0088),\n",
       " tensor(0.0085),\n",
       " tensor(0.0075),\n",
       " tensor(0.0069),\n",
       " tensor(0.0068),\n",
       " tensor(0.0066),\n",
       " tensor(0.0063),\n",
       " tensor(0.0063),\n",
       " tensor(0.0063),\n",
       " tensor(0.0062),\n",
       " tensor(0.0056),\n",
       " tensor(0.0050),\n",
       " tensor(0.0050),\n",
       " tensor(0.0049),\n",
       " tensor(0.0047),\n",
       " tensor(0.0047),\n",
       " tensor(0.0044),\n",
       " tensor(0.0042),\n",
       " tensor(0.0041),\n",
       " tensor(0.0038),\n",
       " tensor(0.0038),\n",
       " tensor(0.0038),\n",
       " tensor(0.0038),\n",
       " tensor(0.0034),\n",
       " tensor(0.0031),\n",
       " tensor(0.0031),\n",
       " tensor(0.0030),\n",
       " tensor(0.0027),\n",
       " tensor(0.0025),\n",
       " tensor(0.0025),\n",
       " tensor(0.0024),\n",
       " tensor(0.0024),\n",
       " tensor(0.0024),\n",
       " tensor(0.0024),\n",
       " tensor(0.0023),\n",
       " tensor(0.0021),\n",
       " tensor(0.0019),\n",
       " tensor(0.0019),\n",
       " tensor(0.0019),\n",
       " tensor(0.0018),\n",
       " tensor(0.0013),\n",
       " tensor(0.0013),\n",
       " tensor(0.0013),\n",
       " tensor(0.0012),\n",
       " tensor(0.0010),\n",
       " tensor(0.0008),\n",
       " tensor(0.0007),\n",
       " tensor(0.0006),\n",
       " tensor(0.0006),\n",
       " tensor(0.0005),\n",
       " tensor(0.0004),\n",
       " tensor(0.0001),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " ...]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(avg_da - avg_en, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4672)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(avg_da - avg_en)[max_diff_neuron]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_preacts_tnsr = torch.stack(da_preacts).detach()\n",
    "en_preacts_tnsr = torch.stack(en_preacts).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_difference_by_neuron(da_preacts, en_preacts, neuron):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 4))\n",
    "\n",
    "    ax.set_title(f'Neuron {neuron}')\n",
    "    ax.hist(da_preacts[:, neuron], bins=30, alpha=0.5, color='blue')\n",
    "    ax.hist(en_preacts[:, neuron], bins=30, alpha=0.5, color='orange')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bruger\\AppData\\Local\\Temp\\ipykernel_21004\\2055940904.py:9: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  fig.show()\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_difference_by_neuron(da_preacts_tnsr, en_preacts_tnsr, 398)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
